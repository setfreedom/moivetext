#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å½±è§†è§£è¯´é¡¹ç›® - ç¬¬å››æ­¥ï¼šä½¿ç”¨ ModelScope å†…ç½®çš„ CosyVoice åˆæˆè¯­éŸ³ï¼ˆæ­£ç¡®æ–¹å¼ï¼‰
"""

import os
import re
import torch
import soundfile as sf

# å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆæ—  GPUï¼‰
torch.set_num_threads(4)

def split_sentences(text):
    sentences = re.split(r'(?<=[ã€‚ï¼Ÿï¼â€¦])\s*', text.strip())
    return [s.strip() for s in sentences if s.strip()]

def main():
    INPUT_SCRIPT = "output_step3/movie_script.txt"
    OUTPUT_DIR = "output_step4/audio"
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    with open(INPUT_SCRIPT, "r", encoding="utf-8") as f:
        script = f.read()
    
    sentences = split_sentences(script)
    print(f"å…±åˆ‡åˆ†ä¸º {len(sentences)} å¥")

    # âœ… å…³é”®ï¼šç›´æ¥å¯¼å…¥ CosyVoice æ¨¡å‹ç±»
    from modelscope.models.audio.tts.cosyvoice import CosyVoiceModel
    from modelscope.pipelines.audio.tts_pipeline import TextToSpeechPipeline

    print("æ­£åœ¨åŠ è½½ CosyVoice æ¨¡å‹...")
    model = CosyVoiceModel.from_pretrained('iic/CosyVoice-300M')
    pipeline = TextToSpeechPipeline(model=model, device='cpu')

    for i, sentence in enumerate(sentences, 1):
        print(f"[{i}/{len(sentences)}] åˆæˆ: {sentence[:40]}...")
        try:
            # è°ƒç”¨ pipeline
            result = pipeline(input=sentence, voice='ä¸­æ–‡å¥³')
            audio = result['output_wav']
            sf.write(os.path.join(OUTPUT_DIR, f"audio_{i:03d}.wav"), audio, 22050)
            print(f"âœ… ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")

    print("ğŸ‰ è¯­éŸ³åˆæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()